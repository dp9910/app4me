# State-of-the-Art App Recommendation System
## Enhanced Architecture with Gemini AI

---

## Executive Summary

Build a **hybrid multi-signal recommendation system** that combines:
1. **Semantic Search** (Gemini embeddings) - for intent understanding
2. **Keyword Matching** (TF-IDF + taxonomy) - for precision
3. **Collaborative Filtering** - for personalization
4. **Neural Re-ranking** (Gemini LLM) - for final ordering
5. **Multi-Armed Bandit** - for exploration/exploitation balance
6. **Feedback Loop** - continuous learning from user behavior

**Key Innovation:** Layer multiple retrieval strategies, then use Gemini to intelligently re-rank based on user context.

---

## System Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER QUERY INPUT                          â”‚
â”‚         "I eat out a lot and need to budget"                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               QUERY UNDERSTANDING LAYER                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Gemini Embeddingâ”‚  â”‚ Keyword      â”‚  â”‚ Intent         â”‚ â”‚
â”‚  â”‚ Generation      â”‚  â”‚ Extraction   â”‚  â”‚ Classification â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             MULTI-SIGNAL RETRIEVAL LAYER                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚   Semantic   â”‚ â”‚   Keyword    â”‚ â”‚   Collaborative      â”‚â”‚
â”‚  â”‚   Search     â”‚ â”‚   Matching   â”‚ â”‚   Filtering          â”‚â”‚
â”‚  â”‚ (Vector DB)  â”‚ â”‚  (TF-IDF)    â”‚ â”‚ (User Similarity)    â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚         â”‚                â”‚                    â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â†“ (Candidate Pool: 50-100 apps)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FUSION & SCORING LAYER                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Reciprocal Rank Fusion (RRF)                        â”‚   â”‚
â”‚  â”‚  â€¢ Combine scores from all retrieval methods         â”‚   â”‚
â”‚  â”‚  â€¢ Weight by confidence and user history             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â†“ (Top 30 candidates)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              NEURAL RE-RANKING LAYER (Gemini)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Gemini LLM Contextual Re-ranking                    â”‚   â”‚
â”‚  â”‚  â€¢ Analyze user profile + query context              â”‚   â”‚
â”‚  â”‚  â€¢ Score each app's relevance (1-10)                 â”‚   â”‚
â”‚  â”‚  â€¢ Generate personalized one-liners                  â”‚   â”‚
â”‚  â”‚  â€¢ Explain why each app matches                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â†“ (Top 10 results)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DIVERSITY & EXPLORATION LAYER                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Multi-Armed Bandit (Thompson Sampling)              â”‚   â”‚
â”‚  â”‚  â€¢ 70% exploitation (top ranked)                     â”‚   â”‚
â”‚  â”‚  â€¢ 20% exploration (high potential)                  â”‚   â”‚
â”‚  â”‚  â€¢ 10% serendipity (random good apps)                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FINAL RESULTS (10 apps)                    â”‚
â”‚        + Personalized one-liners + Match explanations       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FEEDBACK LOOP                             â”‚
â”‚  User interactions â†’ Update weights â†’ Retrain models        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Phase 1: Data Enrichment Pipeline

### 1.1 App Feature Engineering

**Extract 5 types of features from your 9,183 apps:**

```javascript
// /lib/recommendation/feature-engineering.js

export async function enrichAppData(app) {
  return {
    // 1. Structured Metadata Features
    metadata: {
      category_primary: app.primary_category,
      category_all: app.all_categories,
      price_tier: classifyPriceTier(app.price),
      rating_tier: classifyRatingTier(app.rating_average),
      popularity_score: calculatePopularity(app.rating_count, app.downloads_estimate),
      recency_score: calculateRecency(app.release_date, app.last_updated),
      developer_reputation: calculateDevReputation(app.developer_id)
    },
    
    // 2. TF-IDF Keywords (from your plan)
    keywords_tfidf: await extractTFIDFKeywords(app.full_description),
    
    // 3. LLM-Extracted Structured Data
    llm_features: await extractLLMFeatures(app),
    
    // 4. Semantic Embedding (Gemini)
    embedding: await generateGeminiEmbedding(app),
    
    // 5. Behavioral Features (once we have user data)
    behavioral: {
      click_through_rate: 0,
      conversion_rate: 0,
      avg_session_time: 0,
      like_rate: 0
    }
  };
}

async function extractLLMFeatures(app) {
  const prompt = `Analyze this app and extract structured information:

App: ${app.name}
Category: ${app.primary_category}
Description: ${app.full_description}

Extract and return JSON with:
{
  "primary_use_case": "single most common use case",
  "use_cases": ["use case 1", "use case 2", "use case 3"],
  "target_personas": ["persona 1", "persona 2"],
  "problem_solved": "main problem this solves",
  "key_features": ["feature 1", "feature 2", "feature 3"],
  "limitations": ["limitation 1", "limitation 2"],
  "best_for_keywords": ["keyword1", "keyword2", "keyword3"],
  "not_good_for": ["scenario 1", "scenario 2"],
  "emotional_tone": "professional|casual|playful|serious",
  "complexity_level": "beginner|intermediate|advanced",
  "time_commitment": "quick|moderate|intensive"
}

Return ONLY valid JSON:`;

  const result = await geminiModel.generateContent(prompt);
  return JSON.parse(result.response.text().match(/\{[\s\S]*\}/)[0]);
}
```

### 1.2 Build Comprehensive App Index

```sql
-- Enhanced schema for recommendation features
CREATE TABLE app_features (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  app_id UUID REFERENCES apps(id) UNIQUE,
  
  -- TF-IDF Keywords (from original plan)
  keywords_tfidf JSONB, -- {"budget": 0.92, "expense": 0.88, ...}
  keyword_categories JSONB, -- {"budget": ["finance", "productivity"], ...}
  
  -- LLM-extracted structured features
  primary_use_case TEXT,
  use_cases TEXT[],
  target_personas TEXT[],
  problem_solved TEXT,
  key_features TEXT[],
  limitations TEXT[],
  best_for_keywords TEXT[],
  not_good_for TEXT[],
  emotional_tone TEXT,
  complexity_level TEXT,
  time_commitment TEXT,
  
  -- Semantic embedding (Gemini 768-dim)
  embedding VECTOR(768),
  
  -- Popularity & Quality Signals
  popularity_score DECIMAL,
  quality_score DECIMAL,
  recency_score DECIMAL,
  
  -- Collaborative filtering features
  similar_app_ids UUID[],
  complementary_app_ids UUID[],
  
  -- Behavioral metrics (updated from user interactions)
  total_impressions INTEGER DEFAULT 0,
  total_clicks INTEGER DEFAULT 0,
  total_likes INTEGER DEFAULT 0,
  total_installs INTEGER DEFAULT 0,
  ctr DECIMAL DEFAULT 0,
  like_rate DECIMAL DEFAULT 0,
  
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);

-- Indexes for fast retrieval
CREATE INDEX idx_features_embedding ON app_features USING ivfflat (embedding vector_cosine_ops);
CREATE INDEX idx_features_keywords ON app_features USING gin (keywords_tfidf);
CREATE INDEX idx_features_use_cases ON app_features USING gin (use_cases);
CREATE INDEX idx_features_personas ON app_features USING gin (target_personas);

-- Category taxonomy (from your plan, enhanced)
CREATE TABLE keyword_taxonomy (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  keyword TEXT NOT NULL,
  category TEXT NOT NULL,
  tier TEXT NOT NULL, -- 'primary', 'secondary', 'modifier'
  base_weight DECIMAL(3,2) NOT NULL,
  synonyms TEXT[] DEFAULT '{}',
  related_keywords TEXT[] DEFAULT '{}',
  intent_type TEXT, -- 'functional', 'emotional', 'contextual'
  created_at TIMESTAMP DEFAULT NOW()
);

-- User profiles for collaborative filtering
CREATE TABLE user_profiles (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id TEXT UNIQUE,
  
  -- Explicit preferences
  lifestyle_tags TEXT[],
  preferred_categories TEXT[],
  
  -- Implicit preferences (learned)
  liked_app_ids UUID[],
  viewed_app_ids UUID[],
  rejected_app_ids UUID[],
  
  -- Feature preferences (learned from interactions)
  preferred_keywords JSONB, -- {"budget": 0.8, "visual": 0.6}
  preferred_use_cases TEXT[],
  preferred_complexity TEXT, -- 'beginner', 'intermediate', 'advanced'
  
  -- Embedding (average of liked apps)
  preference_embedding VECTOR(768),
  
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);

-- Interaction tracking for learning
CREATE TABLE recommendation_events (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  
  -- Context
  user_id TEXT,
  session_id TEXT,
  query TEXT,
  query_embedding VECTOR(768),
  extracted_intent JSONB,
  
  -- Recommendations shown
  recommended_apps JSONB, -- [{"app_id": "...", "score": 0.95, "rank": 1, "method": "semantic"}]
  
  -- User actions
  clicked_app_ids UUID[],
  liked_app_ids UUID[],
  rejected_app_ids UUID[],
  installed_app_ids UUID[],
  
  -- Feedback
  explicit_rating INTEGER, -- 1-5 if user rates the recommendations
  session_duration_seconds INTEGER,
  
  created_at TIMESTAMP DEFAULT NOW()
);

-- Multi-armed bandit state
CREATE TABLE bandit_arms (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  app_id UUID REFERENCES apps(id) UNIQUE,
  
  -- Thompson Sampling parameters
  alpha DECIMAL DEFAULT 1.0, -- successes + 1
  beta DECIMAL DEFAULT 1.0,  -- failures + 1
  
  -- Statistics
  total_impressions INTEGER DEFAULT 0,
  total_clicks INTEGER DEFAULT 0,
  estimated_ctr DECIMAL DEFAULT 0,
  confidence_interval DECIMAL DEFAULT 1.0,
  
  updated_at TIMESTAMP DEFAULT NOW()
);
```

---

## Phase 2: Multi-Signal Retrieval System

### 2.1 Semantic Search (Primary Signal)

```javascript
// /lib/recommendation/retrievers/semantic-retriever.js

export async function semanticRetrieval(query, userProfile, limit = 30) {
  // Generate query embedding
  const embeddingModel = genAI.getGenerativeModel({ 
    model: 'text-embedding-004' 
  });
  
  // Enrich query with user context
  const enrichedQuery = `
    User query: ${query}
    User preferences: ${userProfile?.lifestyle_tags?.join(', ') || 'general'}
    User history: ${userProfile?.preferred_use_cases?.join(', ') || 'none'}
  `.trim();
  
  const result = await embeddingModel.embedContent(enrichedQuery);
  const queryEmbedding = result.embedding.values;
  
  // Vector similarity search
  const { data: matches } = await supabase.rpc('semantic_search_apps', {
    query_embedding: queryEmbedding,
    match_threshold: 0.5,
    match_count: limit,
    user_rejected_ids: userProfile?.rejected_app_ids || []
  });
  
  return matches.map(m => ({
    ...m,
    retrieval_method: 'semantic',
    retrieval_score: m.similarity
  }));
}

// SQL function for semantic search
CREATE OR REPLACE FUNCTION semantic_search_apps(
  query_embedding VECTOR(768),
  match_threshold FLOAT,
  match_count INT,
  user_rejected_ids UUID[] DEFAULT '{}'
)
RETURNS TABLE (
  app_id UUID,
  similarity FLOAT,
  app_data JSONB
)
LANGUAGE plpgsql
AS $$
BEGIN
  RETURN QUERY
  SELECT
    af.app_id,
    1 - (af.embedding <=> query_embedding) AS similarity,
    jsonb_build_object(
      'name', a.name,
      'category', a.primary_category,
      'rating', a.rating_average,
      'use_cases', af.use_cases,
      'icon_url', a.icon_url_512
    ) AS app_data
  FROM app_features af
  JOIN apps a ON a.id = af.app_id
  WHERE 
    a.is_active = true
    AND af.app_id != ALL(user_rejected_ids)
    AND 1 - (af.embedding <=> query_embedding) > match_threshold
  ORDER BY af.embedding <=> query_embedding
  LIMIT match_count;
END;
$$;
```

### 2.2 Keyword Matching (Precision Signal)

```javascript
// /lib/recommendation/retrievers/keyword-retriever.js

export async function keywordRetrieval(query, limit = 30) {
  // Extract keywords using NLP
  const keywords = await extractKeywords(query);
  
  // Map to taxonomy
  const taxonomyKeywords = await mapToTaxonomy(keywords);
  
  // TF-IDF scoring
  const { data: matches } = await supabase.rpc('keyword_search_apps', {
    search_keywords: taxonomyKeywords.map(k => k.keyword),
    keyword_weights: taxonomyKeywords.map(k => k.weight),
    match_count: limit
  });
  
  return matches.map(m => ({
    ...m,
    retrieval_method: 'keyword',
    retrieval_score: m.keyword_score
  }));
}

async function extractKeywords(query) {
  const prompt = `Extract important keywords from this query. Return JSON array of objects with "keyword" and "weight" (0-1).

Query: "${query}"

Focus on: actions, objects, contexts, constraints.
Example: [{"keyword": "track", "weight": 0.9}, {"keyword": "budget", "weight": 0.95}]

Return ONLY JSON array:`;

  const result = await geminiModel.generateContent(prompt);
  return JSON.parse(result.response.text().match(/\[[\s\S]*\]/)[0]);
}

// SQL function
CREATE OR REPLACE FUNCTION keyword_search_apps(
  search_keywords TEXT[],
  keyword_weights DECIMAL[],
  match_count INT
)
RETURNS TABLE (
  app_id UUID,
  keyword_score DECIMAL,
  matched_keywords TEXT[]
)
LANGUAGE plpgsql
AS $$
BEGIN
  RETURN QUERY
  SELECT
    af.app_id,
    SUM(
      (af.keywords_tfidf->keyword)::DECIMAL * weight
    ) AS keyword_score,
    array_agg(keyword) AS matched_keywords
  FROM app_features af,
       LATERAL unnest(search_keywords, keyword_weights) AS kw(keyword, weight)
  WHERE af.keywords_tfidf ? keyword
  GROUP BY af.app_id
  HAVING SUM((af.keywords_tfidf->keyword)::DECIMAL * weight) > 0.3
  ORDER BY keyword_score DESC
  LIMIT match_count;
END;
$$;
```

### 2.3 Collaborative Filtering (Personalization Signal)

```javascript
// /lib/recommendation/retrievers/collaborative-retriever.js

export async function collaborativeRetrieval(userProfile, limit = 20) {
  if (!userProfile || userProfile.liked_app_ids?.length < 2) {
    return []; // Not enough data for CF
  }
  
  // Find similar users based on liked apps
  const { data: similarUsers } = await supabase.rpc('find_similar_users', {
    user_liked_apps: userProfile.liked_app_ids,
    similarity_threshold: 0.3,
    limit: 50
  });
  
  if (!similarUsers?.length) return [];
  
  // Get apps liked by similar users that current user hasn't seen
  const { data: recommendations } = await supabase.rpc('collaborative_recommendations', {
    similar_user_ids: similarUsers.map(u => u.user_id),
    exclude_app_ids: [
      ...userProfile.liked_app_ids,
      ...userProfile.viewed_app_ids,
      ...userProfile.rejected_app_ids
    ],
    limit
  });
  
  return recommendations.map(r => ({
    ...r,
    retrieval_method: 'collaborative',
    retrieval_score: r.collaborative_score
  }));
}

// SQL functions
CREATE OR REPLACE FUNCTION find_similar_users(
  user_liked_apps UUID[],
  similarity_threshold DECIMAL,
  limit INT
)
RETURNS TABLE (
  user_id TEXT,
  similarity_score DECIMAL
)
LANGUAGE plpgsql
AS $$
BEGIN
  RETURN QUERY
  SELECT
    up.user_id,
    array_length(array_intersect(up.liked_app_ids, user_liked_apps), 1)::DECIMAL / 
    array_length(array_union(up.liked_app_ids, user_liked_apps), 1) AS similarity_score
  FROM user_profiles up
  WHERE 
    up.liked_app_ids && user_liked_apps -- Has overlap
    AND array_length(up.liked_app_ids, 1) >= 3
  HAVING similarity_score >= similarity_threshold
  ORDER BY similarity_score DESC
  LIMIT limit;
END;
$$;
```

### 2.4 Hybrid Retrieval (Content-Based + Behavioral)

```javascript
// /lib/recommendation/retrievers/hybrid-retriever.js

export async function hybridRetrieval(query, userProfile) {
  // Execute all retrievers in parallel
  const [
    semanticResults,
    keywordResults,
    collaborativeResults,
    trendingResults
  ] = await Promise.all([
    semanticRetrieval(query, userProfile, 30),
    keywordRetrieval(query, 30),
    collaborativeRetrieval(userProfile, 20),
    getTrendingApps(userProfile?.preferred_categories, 10)
  ]);
  
  // Combine all candidates
  const allCandidates = [
    ...semanticResults,
    ...keywordResults,
    ...collaborativeResults,
    ...trendingResults
  ];
  
  // Remove duplicates, keeping highest score per app
  const uniqueCandidates = deduplicateByAppId(allCandidates);
  
  // Reciprocal Rank Fusion (RRF)
  const fusedScores = reciprocalRankFusion(uniqueCandidates);
  
  return fusedScores.slice(0, 50); // Top 50 for re-ranking
}

function reciprocalRankFusion(candidates, k = 60) {
  // Group by app_id
  const appGroups = {};
  
  for (const candidate of candidates) {
    if (!appGroups[candidate.app_id]) {
      appGroups[candidate.app_id] = {
        app_id: candidate.app_id,
        app_data: candidate.app_data,
        signals: []
      };
    }
    
    appGroups[candidate.app_id].signals.push({
      method: candidate.retrieval_method,
      score: candidate.retrieval_score,
      rank: candidate.rank || 0
    });
  }
  
  // Calculate RRF score
  const scored = Object.values(appGroups).map(app => {
    const rrfScore = app.signals.reduce((sum, signal) => {
      // Weight different signals
      const weights = {
        semantic: 0.4,
        keyword: 0.3,
        collaborative: 0.2,
        trending: 0.1
      };
      
      const weight = weights[signal.method] || 0.25;
      const rrf = 1 / (k + (signal.rank || 0));
      
      return sum + (weight * rrf);
    }, 0);
    
    return {
      ...app,
      rrf_score: rrfScore,
      signal_count: app.signals.length
    };
  });
  
  // Sort by RRF score
  return scored.sort((a, b) => b.rrf_score - a.rrf_score);
}
```

---

## Phase 3: Neural Re-Ranking with Gemini

### 3.1 Context-Aware Re-ranking

```javascript
// /lib/recommendation/reranker.js

export async function neuralRerank(candidates, query, userProfile) {
  console.log(`ðŸ§  Re-ranking ${candidates.length} candidates with Gemini...`);
  
  const model = genAI.getGenerativeModel({ model: 'gemini-1.5-flash' });
  
  // Process in batches of 10
  const results = [];
  
  for (let i = 0; i < Math.min(candidates.length, 30); i += 10) {
    const batch = candidates.slice(i, i + 10);
    
    const prompt = `You are an expert app recommendation system. Re-rank these apps for relevance to the user.

USER CONTEXT:
Query: "${query}"
Lifestyle: ${userProfile?.lifestyle_tags?.join(', ') || 'general'}
Previous likes: ${userProfile?.preferred_use_cases?.slice(0, 5).join(', ') || 'none'}
Complexity preference: ${userProfile?.preferred_complexity || 'any'}

CANDIDATE APPS (with retrieval signals):
${batch.map((app, idx) => `
${idx + 1}. ${app.app_data.name}
   Category: ${app.app_data.category}
   Use cases: ${app.app_data.use_cases?.join(', ') || 'N/A'}
   Rating: ${app.app_data.rating}/5
   Retrieval methods: ${app.signals.map(s => s.method).join(', ')}
   Initial score: ${app.rrf_score.toFixed(3)}
`).join('\n')}

TASK:
For each app, provide:
1. relevance_score (0-10): How well it matches the user's query and context
2. personalized_oneliner: A custom one-liner in format "If you [user situation], this app [benefit]"
3. match_explanation: Why this app is relevant (1 sentence)
4. confidence: How confident you are in this recommendation (0-1)

Return JSON array:
[
  {
    "app_id": "from candidates",
    "relevance_score": 8.5,
    "personalized_oneliner": "If you...",
    "match_explanation": "...",
    "confidence": 0.9
  }
]

Return ONLY the JSON array:`;

    try {
      const result = await model.generateContent(prompt);
      const text = result.response.text().trim();
      const jsonMatch = text.match(/\[[\s\S]*\]/);
      const parsed = JSON.parse(jsonMatch[0]);
      
      // Merge with original candidates
      for (const reranked of parsed) {
        const original = batch.find(c => c.app_id === reranked.app_id);
        if (original) {
          results.push({
            ...original,
            llm_relevance_score: reranked.relevance_score,
            personalized_oneliner: reranked.personalized_oneliner,
            match_explanation: reranked.match_explanation,
            llm_confidence: reranked.confidence,
            final_score: calculateFinalScore(original, reranked)
          });
        }
      }
    } catch (error) {
      console.error('Re-ranking error:', error);
      // Fallback: use RRF scores
      results.push(...batch.map(c => ({
        ...c,
        final_score: c.rrf_score
      })));
    }
  }
  
  // Sort by final score
  return results.sort((a, b) => b.final_score - a.final_score);
}

function calculateFinalScore(candidate, llmReranking) {
  // Combine RRF score with LLM score
  const rrfWeight = 0.3;
  const llmWeight = 0.7;
  
  const normalizedRRF = candidate.rrf_score; // Already 0-1
  const normalizedLLM = llmReranking.relevance_score / 10; // 0-10 to 0-1
  
  return (rrfWeight * normalizedRRF) + (llmWeight * normalizedLLM);
}
```

---

## Phase 4: Exploration & Diversity

### 4.1 Multi-Armed Bandit (Thompson Sampling)

```javascript
// /lib/recommendation/exploration.js

export async function applyExplorationStrategy(rankedApps, limit = 10) {
  const strategy = {
    exploitation: 0.70, // Top ranked apps
    exploration: 0.20,  // High-potential apps
    serendipity: 0.10   // Random good apps
  };
  
  const exploitCount = Math.floor(limit * strategy.exploitation);
  const exploreCount = Math.floor(limit * strategy.exploration);
  const serendipityCount = limit - exploitCount - exploreCount;
  
  // 1. Exploitation: Top ranked apps
  const exploitation = rankedApps.slice(0, exploitCount);
  
  // 2. Exploration: Thompson Sampling
  const exploration = await thompsonSampling(
    rankedApps.slice(exploitCount, 30),
    exploreCount
  );
  
  // 3. Serendipity: Random highly-rated apps
  const serendipity = await getSerendipityApps(
    rankedApps.map(a => a.app_id),
    serendipityCount
  );
  
  // Interleave for diversity
  return interleaveResults([
    ...exploitation,
    ...exploration,
    ...serendipity
  ], limit);
}

async function thompsonSampling(candidates, count) {
  // Get bandit arms for these apps
  const { data: arms } = await supabase
    .from('bandit_arms')
    .select('*')
    .in('app_id', candidates.map(c => c.app_id));
  
  // Sample from Beta distribution for each app
  const sampled = arms.map(arm => ({
    app_id: arm.app_id,
    sample: betaSample(arm.alpha, arm.beta)
  }));
  
  // Sort by sample and pick top N
  const topSampled = sampled
    .sort((a, b) => b.sample - a.sample)
    .slice(0, count)
    .map(s => s.app_id);
  
  return candidates.filter(c => topSampled.includes(c.app_id));
}

function betaSample(alpha, beta) {
  // Simple beta distribution sampling (use library in production)
  // Using Gamma distributions: Beta(Î±,Î²) = Gamma(Î±) / (Gamma(Î±) + Gamma(Î²))
  const x = gammaSample(alpha);
  const y = gammaSample(beta);
  return x / (x + y);
}

function interleaveResults(apps, limit) {
  // Interleave to ensure diversity
  // Pattern: [exploit, explore, exploit, serendipity, exploit, explore, ...]
  const result = [];
  const buckets = {
    exploitation: apps.filter(a => a.strategy === 'exploitation'),
    exploration: apps.filter(a => a.strategy === 'exploration'),
    serendipity: apps.filter(a => a.strategy === 'serendipity')
  };
  
  let idx = { exploitation: 0, exploration: 0, serendipity: 0 };
  const pattern = ['exploitation', 'exploration', 'exploitation', 'serendipity'];
  
  for (let i = 0; i < limit; i++) {
    const bucket = pattern[i % pattern.length];
    if (buckets[bucket][idx[bucket]]) {
      result.push(buckets[bucket][idx[bucket]]);
      idx[bucket]++;
    }
  }
  
  return result;
}
```

### 4.2 Diversity Injection

```javascript
// Ensure diversity in results
export function ensureDiversity(apps, diversityFactor = 0.3) {
  const diverse = [];
  const usedCategories = new Set();
  const usedUseCases = new Set();
  
  for (const app of apps) {
    // Diversity penalty if category/use_case already shown
    let diversityScore = 1.0;
    
    if (usedCategories.has(app.app_data.category)) {
      diversityScore *= (1 - diversityFactor);
    }
    
    const appUseCases = app.app_data.use_cases || [];
    const overlap = appUseCases.filter(uc => usedUseCases.has(uc)).length;
    if (overlap > 0) {
      diversityScore *= (1 - (overlap / appUseCases.length) * diversityFactor);
    }
    
    app.diversity_score = diversityScore;
    app.final_score *= diversityScore;
    
    diverse.push(app);
    usedCategories.add(app.app_data.category);
    appUseCases.forEach(uc => usedUseCases.add(uc));
  }
  
  return diverse.sort((a, b) => b.final_score - a.final_score);
}
```

---

## Phase 5: Continuous Learning System

### 5.1 Feedback Collection

```javascript
// /lib/recommendation/feedback.js

export async function recordInteraction(event) {
  const {
    userId,
    sessionId,
    query,
    recommendedApps,
    clickedAppIds,
    likedAppIds,
    rejectedAppIds,
    explicitRating
  } = event;
  
  // 1. Store interaction event
  await supabase.from('recommendation_events').insert({
    user_id: userId,
    session_id: sessionId,
    query: query,
    recommended_apps: recommendedApps,
    clicked_app_ids: clickedAppIds,
    liked_app_ids: likedAppIds,
    rejected_app_ids: rejectedAppIds,
    explicit_rating: explicitRating,
    created_at: new Date().toISOString()
  });
  
  // 2. Update user profile
  if (userId) {
    await updateUserProfile(userId, {
      liked_app_ids: likedAppIds,
      viewed_app_ids: clickedAppIds,
      rejected_app_ids: rejectedAppIds
    });
  }
  
  // 3. Update bandit arms
  await updateBanditArms(recommendedApps, clickedAppIds, likedAppIds);
  
  // 4. Update app behavioral metrics
  await updateAppMetrics(recommendedApps, clickedAppIds);
}

async function updateBanditArms(recommended, clicked, liked) {
  for (const rec of recommended) {
    const wasClicked = clicked.includes(rec.app_id);
    const wasLiked = liked.includes(rec.app_id);
    
    // Update Thompson Sampling parameters
    await supabase.rpc('update_bandit_arm', {
      app_id: rec.app_id,
      success: wasClicked || wasLiked,
      failure: !wasClicked && !wasLiked
    });
  }
}

// SQL function
CREATE OR REPLACE FUNCTION update_bandit_arm(
  app_id UUID,
  success BOOLEAN,
  failure BOOLEAN
)
RETURNS VOID
LANGUAGE plpgsql
AS $$
BEGIN
  INSERT INTO bandit_arms (app_id, alpha, beta, total_impressions, total_clicks)
  VALUES (
    app_id,
    CASE WHEN success THEN 2.0 ELSE 1.0 END,
    CASE WHEN failure THEN 2.0 ELSE 1.0 END,
    1,
    CASE WHEN success THEN 1 ELSE 0 END
  )
  ON CONFLICT (app_id) DO UPDATE SET
    alpha = bandit_arms.alpha + CASE WHEN success THEN 1 ELSE 0 END,
    beta = bandit_arms.beta + CASE WHEN failure THEN 1 ELSE 0 END,
    total_impressions = bandit_arms.total_impressions + 1,
    total_clicks = bandit_arms.total_clicks + CASE WHEN success THEN 1 ELSE 0 END,
    estimated_ctr = (bandit_arms.total_clicks + CASE WHEN success THEN 1 ELSE 0 END)::DECIMAL / 
                    (bandit_arms.total_impressions + 1),
    updated_at = NOW();
END;
$$;
```

### 5.2 Model Retraining Pipeline

```javascript
// /lib/recommendation/retrain.js

export async function retrainModels() {
  console.log('ðŸ”„ Starting model retraining...');
  
  // 1. Retrain keyword weights based on successful queries
  await retrainKeywordWeights();
  
  // 2. Update user preference embeddings
  await updateUserEmbeddings();
  
  // 3. Refresh app similarity matrices
  await updateAppSimilarities();
  
  // 4. Recalculate app quality scores
  await recalculateQualityScores();
  
  console.log('âœ… Model retraining complete');
}

async function retrainKeywordWeights() {
  // Analyze successful recommendations
  const { data: successfulEvents } = await supabase
    .from('recommendation_events')
    .select('extracted_intent, clicked_app_ids, liked_app_ids')
    .gte('created_at', new Date(Date.now() - 30 * 24 * 60 * 60 * 1000))
    .not('clicked_app_ids', 'is', null);
  
  // Calculate keyword effectiveness
  const keywordStats = {};
  
  for (const event of successfulEvents) {
    const intent = event.extracted_intent;
    const hadClick = event.clicked_app_ids?.length > 0;
    
    if (intent?.keywords) {
      for (const keyword of intent.keywords) {
        if (!keywordStats[keyword]) {
          keywordStats[keyword] = { total: 0, successes: 0 };
        }
        keywordStats[keyword].total++;
        if (hadClick) keywordStats[keyword].successes++;
      }
    }
  }
  
  // Update taxonomy weights
  for (const [keyword, stats] of Object.entries(keywordStats)) {
    if (stats.total >= 10) { // Minimum sample size
      const successRate = stats.successes / stats.total;
      
      await supabase.from('keyword_taxonomy').upsert({
        keyword: keyword,
        base_weight: successRate,
        updated_at: new Date().toISOString()
      }, { onConflict: 'keyword' });
    }
  }
}

async function updateUserEmbeddings() {
  // For each user, calculate preference embedding
  // Average of embeddings from liked apps
  
  const { data: users } = await supabase
    .from('user_profiles')
    .select('id, user_id, liked_app_ids')
    .gte('array_length(liked_app_ids, 1)', 3);
  
  for (const user of users) {
    const { data: likedApps } = await supabase
      .from('app_features')
      .select('embedding')
      .in('app_id', user.liked_app_ids);
    
    if (likedApps?.length) {
      // Calculate average embedding
      const avgEmbedding = averageEmbeddings(
        likedApps.map(a => a.embedding)
      );
      
      await supabase.from('user_profiles').update({
        preference_embedding: avgEmbedding,
        updated_at: new Date().toISOString()
      }).eq('id', user.id);
    }
  }
}
```

---

## Phase 6: Complete Recommendation API

### 6.1 Main Recommendation Endpoint

```javascript
// /app/api/recommendations/route.js

import { hybridRetrieval } from '@/lib/recommendation/retrievers/hybrid-retriever';
import { neuralRerank } from '@/lib/recommendation/reranker';
import { applyExplorationStrategy } from '@/lib/recommendation/exploration';
import { ensureDiversity } from '@/lib/recommendation/diversity';
import { recordInteraction } from '@/lib/recommendation/feedback';

export async function POST(request) {
  try {
    const { 
      query, 
      userId, 
      sessionId,
      lifestyle,
      improve,
      wishText,
      limit = 10 
    } = await request.json();
    
    console.log('ðŸŽ¯ Recommendation request:', { query, userId });
    
    // 1. Get user profile
    const userProfile = userId 
      ? await getUserProfile(userId)
      : await buildAnonymousProfile(lifestyle, improve, wishText);
    
    // 2. Multi-signal retrieval
    const candidates = await hybridRetrieval(query, userProfile);
    console.log(`ðŸ“¦ Retrieved ${candidates.length} candidates`);
    
    // 3. Neural re-ranking with Gemini
    const reranked = await neuralRerank(
      candidates.slice(0, 30),
      query,
      userProfile
    );
    console.log(`ðŸ§  Re-ranked to ${reranked.length} apps`);
    
    // 4. Apply exploration strategy
    const withExploration = await applyExplorationStrategy(
      reranked,
      limit * 2 // Get more for diversity filtering
    );
    
    // 5. Ensure diversity
    const diverse = ensureDiversity(withExploration);
    
    // 6. Final results
    const finalResults = diverse.slice(0, limit);
    
    // 7. Prepare response
    const recommendations = finalResults.map((app, index) => ({
      rank: index + 1,
      app_id: app.app_id,
      name: app.app_data.name,
      category: app.app_data.category,
      icon_url: app.app_data.icon_url,
      rating: app.app_data.rating,
      personalized_oneliner: app.personalized_oneliner,
      match_explanation: app.match_explanation,
      retrieval_methods: app.signals?.map(s => s.method) || [],
      confidence: app.llm_confidence,
      strategy: app.strategy || 'exploitation'
    }));
    
    // 8. Return recommendations
    return NextResponse.json({
      success: true,
      query: query,
      recommendations: recommendations,
      metadata: {
        total_candidates: candidates.length,
        retrieval_time_ms: Date.now() - startTime,
        user_profile_used: !!userId
      }
    });
    
  } catch (error) {
    console.error('Recommendation error:', error);
    return NextResponse.json(
      { success: false, error: error.message },
      { status: 500 }
    );
  }
}
```

---

## Implementation Timeline

### Week 1-2: Data Enrichment
- [x] Run TF-IDF keyword extraction on 9,183 apps
- [x] Generate Gemini embeddings for all apps (768-dim)
- [x] Use Gemini to extract structured features (use cases, personas, etc.)
- [x] Build keyword taxonomy from your plan
- [x] Create app_features table with all signals

### Week 3: Build Retrievers
- [x] Implement semantic search (Gemini embeddings)
- [x] Implement keyword matching (TF-IDF + taxonomy)
- [x] Implement hybrid retrieval with RRF fusion
- [x] Build SQL functions for fast retrieval

### Week 4: Neural Re-ranking
- [x] Implement Gemini-powered re-ranker
- [x] Add context-aware scoring
- [x] Generate personalized one-liners
- [x] Batch processing for efficiency

### Week 5: Exploration & Learning
- [x] Implement Thompson Sampling (bandit)
- [x] Add diversity injection
- [x] Build feedback collection system
- [x] Create retraining pipeline

### Week 6: Integration & Testing
- [x] Build complete API endpoint
- [x] Add monitoring and logging
- [x] A/B testing framework
- [x] Performance optimization

---

## Success Metrics

### Recommendation Quality
- **Precision@10:** >70% of top 10 are relevant
- **Click-through rate:** >15%
- **Like rate:** >25% of clicked apps
- **Average session time:** >3 minutes

### System Performance
- **Latency P95:** <500ms for recommendations
- **Throughput:** 100+ requests/second
- **Cache hit rate:** >60%

### Learning Effectiveness
- **CTR improvement:** +10% per month
- **Keyword weight convergence:** <5% change after 1000 queries
- **User satisfaction:** 4.5+ rating

---

## Advanced Optimizations

### 1. Cold Start Problem
```javascript
// For new apps with no interactions
async function coldStartScore(app) {
  return {
    quality_score: calculateQualityScore(app),
    semantic_relevance: 0.5, // Neutral
    exploration_bonus: 0.2   // Boost new apps
  };
}
```

### 2. Real-time Personalization
```javascript
// Update user embedding in real-time during session
async function updateSessionProfile(sessionId, clickedApp) {
  // Exponential moving average
  const alpha = 0.3;
  const newEmbedding = await getAppEmbedding(clickedApp);
  
  sessionProfile.embedding = 
    alpha * newEmbedding + (1 - alpha) * sessionProfile.embedding;
}
```

### 3. Contextual Bandits
```javascript
// Context-aware exploration
async function contextualThompsonSampling(apps, context) {
  // Use context features (time of day, device, etc.) to adjust sampling
  const timeOfDay = getTimeOfDay();
  const contextWeight = contextWeights[timeOfDay] || 1.0;
  
  return apps.map(app => ({
    ...app,
    adjusted_alpha: app.alpha * contextWeight
  }));
}
```

---

## Cost Analysis (with 9,183 apps)

### One-time Processing
- **Embeddings:** 9,183 apps Ã— $0.00001 = **$0.09**
- **LLM features:** 9,183 apps Ã— $0.002 = **$18.37**
- **Total:** **~$20** (one-time)

### Ongoing (per month)
- **Recommendations:** 10,000 queries Ã— $0.002 = **$20**
- **Re-ranking:** 10,000 queries Ã— $0.001 = **$10**
- **Retraining:** Weekly Ã— $5 = **$20**
- **Total:** **~$50/month** at 10K queries

### At Scale (100K queries/month)
- **~$500/month** (still very affordable!)

---

## Key Takeaways

This system is **state-of-the-art** because it:

1. âœ… **Multi-signal retrieval** - Not just semantic, but keyword + collaborative + trending
2. âœ… **Neural re-ranking** - LLM understands context and personalizes
3. âœ… **Exploration/exploitation** - Balances known good apps with discovery
4. âœ… **Continuous learning** - Gets better with every interaction
5. âœ… **Diversity** - Prevents filter bubbles and echo chambers
6. âœ… **Scalable** - Can handle millions of queries efficiently
7. âœ… **Practical** - Uses free/cheap Gemini API, not expensive infrastructure

**Most importantly:** It's implementable RIGHT NOW with your existing 9,183 apps and Gemini access! ðŸš€